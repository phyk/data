---
title: "Programming Data Science Report"
author: "Philipp Peter, Laurenz Harnischmacher, Nico Lindert"
date: "24 Mai 2019"
output: 
  bookdown::html_document2:
    toc: yes 
    toc_float: true
---
```{r importLibs, include=FALSE}
# load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(stringi)
library(hms)
library(knitr)
```

```{r furtherPrep, include=FALSE}
require("knitr")

# Set root directory
knitr::opts_knit$set(root.dir = "C:/Github/data")
rootDir <- knitr::opts_knit$get("root.dir")
headersPath <- paste(rootDir, "01_data_understanding/order_columns.txt", sep="/")
headersPath2 <- paste(rootDir, "01_data_understanding/clickstream_columns.txt", sep="/")
# # initially
# dataPath <- paste(rootDir, "00_raw_data/order_data.csv", sep="/")
# dataPath2 <- paste(rootDir, "00_raw_data/clickstream_data.csv", sep="/")
dataPath <- paste(rootDir, "02_data_preparation/order_data_clean.csv", sep="/")
dataPath2 <- paste(rootDir, "02_data_preparation/click_data_clean.csv", sep="/")

knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This course simulated a data science project. Within this course, a webshop's dataset from 2000 will be imported, cleaned, analyzed and evaluated. <br>
The process is separated into the following steps:<br>

* [Data manipulation]
* [Visualization] using a grammar of graphics
* [Summary tables]
* [Comparison of groups] (treatment effect)
* [Predictions] (bias, variance, complexity factor)


## Motivation

In times of big data and the importance of evaluating company's data to stay competible on a highly digitized market, data science provides powerful tools to handle these challenges.<br>

< more blabla >


## Data Import

At first, the csv-files containting data will be imported.

```{r dataImport, echo=FALSE, warning=FALSE, message=FALSE}
# prepare column name list
headersFile = file(headersPath, "r")
headersFile2 = file(headersPath2, "r")
#headerNames <- list()
#http://r.789695.n4.nabble.com/How-to-read-plain-text-documents-into-a-vector-td901794.html
obj_list <- readLines(headersFile)
obj_list2 <- readLines(headersFile2)

#To convert to a vector, do the following:
result <- stri_extract_first(obj_list, regex="[A-z ,]+")
result2 <- stri_extract_first(obj_list2, regex="[A-z ,]+")
dtype <- stri_extract_last(obj_list, regex="[A-z ,]+")
result <- gsub(" ", "_", result)
result2 <- gsub(" ", "_", result2)

# initially
# order_df <- read_csv(dataPath, col_names = result, na=c("", "?", "NULL", "NA", "Nan"))
# click_df <- read_csv(dataPath2, col_names = result2, na=c("", "?", "NULL", "NA", "Nan"))

order_df <- read_csv(dataPath, na=c("", "?", "NULL", "NA", "Nan"))
click_df <- read_csv(dataPath2, na=c("", "?", "NULL", "NA", "Nan"))

# Parse Order Time
order_df$Order_Time <- parse_time(order_df$"Order_Line_Date_Time","%H\\:%M\\:%S")
```


# Analysis

## Data Manipulation {#dataMan}

Due to the huge size of the datasets, we will

1. create a new set `relevant_df` with the 16 most relevant columns
1. reduce the original set `order_df` by deleting all twin columns

Besides, all semicolons within the cells were simply erased.

```{r dataClean, echo=FALSE}
# Selected Column Indices
sel <- c("Order_Session_ID","Order_Date","Order_Time","Order_ID","Order_Status","Order_Amount","HowDidYouHearAboutUs","City","US_State","Year_of_Birth","Customer_ID","Estimated_Income_Code","Gender","Order_Credit_Card_Brand","BrandName","Product_Object_ID","Assortment_ID")
sel2 <- c("Session_ID","Request_Sequence","Request_Processing_Time","Request_Query_String","Request_Referrer","Request_Date","Request_Date_Time","Request_Assortment_ID","Request_Subassortment_ID","Request_Template","REQUEST_DAY_OF_WEEK","Product_ID")

or <- select(order_df,sel)
cl <- select(click_df, sel2)

# Get rid of semicolons
or$Estimated_Income_Code <- gsub(";", "", or$Estimated_Income_Code)

#write.csv(or, "order_data_clean.csv")
#write.csv(cl, "click_data_clean.csv")
```

```{r grammarofg}
#x = as.POSIXct(paste(or$Order_Date, or$Order_Time), format="%Y-%m-%d %H:%M:%S")

ggplot(or) +
  geom_point(mapping = aes(x = Order_Time, y = Order_Amount, color = Gender))

or$Estimated_Income_Code <- factor(or$Estimated_Income_Code, levels = c(
  "Under $15000", "$15000-$19999", "$20000-$29999", "$30000-$39999", "$40000-$49999",
  "$50000-$74999", "$75000-$99999", "$100000-$124999", "$125000 OR MORE"
))

boxplot(Order_Amount~Gender, data = order_df, horizontal = TRUE)
boxplot(Order_Amount~Estimated_Income_Code, data = order_df)

```




```{r FUNKTIONIERTNICHT}
# Vergleiche Spalten bei clicks, ob Dopplungen vorkommen
dataframe <- cl

drop <- vector()
k <- 1
for (i in 1:ncol(dataframe)) {
  col_i = colnames(dataframe)[i]
  for (j in i+1:ncol(dataframe)){
    col_j = colnames(dataframe)[j]
    if(identical(dataframe[[col_i]],dataframe[[col_j]])) {
      #print(paste(col_i,col_j,sep=" = "))
      drop[k] <- i
      k <- k+1
    }
  }
}
# print(drop)
# Loesche doppelte Spalten (immer die 1.)
cl <- subset(dataframe, select = -drop)

# Vergleiche Spalten bei order, ob Dopplungen vorkommen
dataframe <- or

drop <- vector()
k <- 1
for (i in 1:ncol(dataframe)) {
  col_i = colnames(dataframe)[i]
  for (j in i+1:ncol(dataframe)){
    col_j = colnames(dataframe)[j]
    if(identical(dataframe[[col_i]],dataframe[[col_j]])) {
      #print(paste(col_i,col_j,sep=" = "))
      drop[k] <- i
      k <- k+1
    }
  }
}
# print(drop)
# Loesche doppelte Spalten (immer die 1.)
or <- subset(dataframe, select = -drop)
```


## Visualisation

On a first look, the data provides the following information.

```{r firstLook, echo = FALSE, warning = FALSE}
summary_stats <- order_df %>% # start with data frame, and then ...
  summarize_at(
    .vars = c("Order_Date", "Order_Time", "Order_Amount"), # select variables, that should be in the table
    .funs = funs(min, max, mean, median, sd) # which summary statistics do you want
  ) %>%
  gather (key, value) %>% # transpose everthing, and then ...
  separate(col=key, sep="_", c("object", "feature", "stat")) %>% # make the two columns out of var name
  spread(key=stat, value=value) %>% # repeated obs into multiple columns
  select(-"object")
kable(summary_stats)
```
Thereby, date and time are less useful, as the time-format is transformed into double values that provide no information on a first look.




## Summary tables

```{r summary, echo=FALSE}

```


## Comparison of groups

```{r compare, echo=FALSE}

```


## Predictions

```{r prediction, echo=FALSE}

```

# Conclusion
