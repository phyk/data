---
title: "Programming Data Science Report"
author: "Philipp Peter, Laurenz Harnischmacher, Nico Lindert"
date: "24 Mai 2019"
output: 
  bookdown::html_document2:
    toc: yes 
    toc_float: true
---
```{r importLibs, include=FALSE}
# load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(stringi)
library(hms)
library(knitr)
```

```{r furtherPrep, include=FALSE}
require("knitr")

# Set root directory
knitr::opts_knit$set(root.dir = "C:/Github/data")
rootDir <- knitr::opts_knit$get("root.dir")
headersPath <- paste(rootDir, "01_data_understanding/order_columns.txt", sep="/")
headersPath2 <- paste(rootDir, "01_data_understanding/clickstream_columns.txt", sep="/")
dataPath <- paste(rootDir, "00_raw_data/order_data.csv", sep="/")
dataPath2 <- paste(rootDir, "00_raw_data/clickstream_data.csv", sep="/")

knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This course simulated a data science project. Within this course, a webshop's dataset from 2000 will be imported, cleaned, analyzed and evaluated. <br>
The process is separated into the following steps:<br>

* [Data manipulation]
* [Visualization] using a grammar of graphics
* [Summary tables]
* [Comparison of groups] (treatment effect)
* [Predictions] (bias, variance, complexity factor)


## Motivation

In times of big data and the importance of evaluating company's data to stay competible on a highly digitized market, data science provides powerful tools to handle these challenges.<br>

< more blabla >


## Data Import

At first, the csv-files containting data will be imported.

```{r dataImport, echo=FALSE, warning=FALSE, message=FALSE}
# prepare column name list
headersFile = file(headersPath, "r")
headersFile2 = file(headersPath2, "r")
#headerNames <- list()
#http://r.789695.n4.nabble.com/How-to-read-plain-text-documents-into-a-vector-td901794.html
obj_list <- readLines(headersFile)
obj_list2 <- readLines(headersFile2)

#To convert to a vector, do the following:
result <- stri_extract_first(obj_list, regex="[A-z ,]+")
result2 <- stri_extract_first(obj_list2, regex="[A-z ,]+")
dtype <- stri_extract_last(obj_list, regex="[A-z ,]+")
result <- gsub(" ", "_", result)
result2 <- gsub(" ", "_", result2)

order_df <- read_csv(dataPath, col_names = result, na=c("", "?", "NULL", "NA", "Nan"), guess_max = 3400)
#Schafft Laptop nicht
#click_df <- read_csv(dataPath2, col_names = result2, na=c("", "?", "NULL", "NA", "Nan"), guess_max = 3400)

# Parse Order Time
order_df$Order_Time <- parse_time(order_df$"Order_Line_Date_Time","%H\\:%M\\:%S")
```


# Analysis

## Data Manipulation {#dataMan}

Due to the huge size of the datasets, we will

1. create a new set `relevant_df` with the 16 most relevant columns
1. reduce the original set `order_df` by deleting all twin columns

Besides, all semicolons within the cells were simply erased.

```{r dataClean, echo=FALSE}
# Selected Column Indices
sel <- c(115,116,120,189,233,121,39,101,107,130,135,58,25,30,32,35)

relevant_df <- select(order_df,sel)

# Vergleiche Spalten, ob Dopplungen vorkommen
dataframe <- order_df

drop <- vector()
k <- 1
for (i in 1:ncol(dataframe)) {
  col_i = colnames(dataframe)[i]
  for (j in i+1:ncol(dataframe)){
    col_j = colnames(dataframe)[j]
    if(identical(dataframe[[col_i]],dataframe[[col_j]])) {
      # print(paste(col_i,col_j,sep=" = "))
      drop[k] <- i
      k <- k+1
    }
  }
}
# print(drop)
# Loesche doppelte Spalten (immer die 1.)
order_df <- subset(dataframe, select = -drop)

# Get rid of semicolons
order_df$Estimated_Income_Code <- gsub(";", "", order_df$Estimated_Income_Code)
relevant_df$Estimated_Income_Code <- gsub(";", "", relevant_df$Estimated_Income_Code)
```


## Visualisation

On a first look, the data provides the following information.

```{r firstLook, echo = FALSE, warning = FALSE}
summary_stats <- order_df %>% # start with data frame, and then ...
  summarize_at(
    .vars = c("Order_Date", "Order_Time", "Order_Amount"), # select variables, that should be in the table
    .funs = funs(min, max, mean, median, sd) # which summary statistics do you want
  ) %>%
  gather (key, value) %>% # transpose everthing, and then ...
  separate(col=key, sep="_", c("object", "feature", "stat")) %>% # make the two columns out of var name
  spread(key=stat, value=value) %>% # repeated obs into multiple columns
  select(-"object")
kable(summary_stats)
```
Thereby, date and time are less useful, as the time-format is transformed into double values that provide no information on a first look.




## Summary tables

```{r summary, echo=FALSE}

```


## Comparison of groups

```{r compare, echo=FALSE}

```


## Predictions

```{r prediction, echo=FALSE}

```

# Conclusion
