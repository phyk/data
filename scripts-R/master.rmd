---
title: "Programming Data Science Report"
author: "Philipp Peter, Laurenz Harnischmacher, Nico Lindert"
date: "24 Mai 2019"
output: 
  bookdown::html_document2:
    toc: yes 
    toc_float: true
---
```{r importLibs, include=FALSE}
# load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(stringi)
library(hms)
library(knitr)
```

## move dataset to raw_data
```{r warning=FALSE}

rootDir <- knitr::opts_knit$get("root.dir")
origin_clickstream <- paste(rootDir, "clickstream", sep="/")
origin_experiment <- paste(rootDir,"experiment", sep="/")
origin_orders <- paste(rootDir,"orders", sep="/")

des_root <- paste(rootDir, "00_raw_data", sep="/")
des_under <- paste(rootDir, "01_data_understanding", sep="/")

# move datasets
# clickstream1
unzip(paste(origin_clickstream,"clickstream_data.zip",sep="/"),files= "clickstream_data.csv",list = FALSE, exdir = des_root)
# clickstream2
file.copy(paste(origin_clickstream,"clickstream_data_part_2.csv",sep="/"),des_root)
# experiment 
file.copy(paste(origin_experiment,"experimental_results.csv", sep = "/"),des_root)
#order
file.copy(paste(origin_orders,"order_data.csv",sep = "/"),des_root)

#move .txts
#clickstream_columns.txt
file.copy(paste(origin_clickstream,"clickstream_columns.txt", sep = "/"),des_under)

#order_columns.txt
file.copy(paste(origin_orders,"order_columns.txt",sep = "/"),des_under)


```

```{r furtherPrep, include=FALSE}
require("knitr")

# Set root directory
#knitr::opts_knit$set(root.dir = "C:/Github/data")
knitr::opts_knit$set(root.dir = "C:\\Users\\Philipp\\Documents\\Meine Dokumente\\StudiumDocs\\Master\\2019 SS\\Programming Data Science\\data")

rootDir <- knitr::opts_knit$get("root.dir")
headersPath <- paste(rootDir, "01_data_understanding/order_columns.txt", sep="/")
headersPath2 <- paste(rootDir, "01_data_understanding/clickstream_columns.txt", sep="/")
dataPath <- paste(rootDir, "00_raw_data/order_data.csv", sep="/")
dataPath2 <- paste(rootDir, "00_raw_data/clickstream_data.csv", sep="/")

knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This course simulated a data science project. Within this course, a webshop's dataset from 2000 will be imported, cleaned, analyzed and evaluated. <br>
The process is separated into the following steps:<br>

* [Data manipulation]
* [Visualization] using a grammar of graphics
* [Summary tables]
* [Comparison of groups] (treatment effect)
* [Predictions] (bias, variance, complexity factor)


## Motivation

In times of big data and the importance of evaluating company's data to stay competible on a highly digitized market, data science provides powerful tools to handle these challenges.<br>

< more blabla >


## Data Import

At first, the csv-files containting data will be imported.

```{r dataImport, echo=FALSE, warning=FALSE, message=FALSE}
# prepare column name list
headersFile = file(headersPath, "r")
headersFile2 = file(headersPath2, "r")
#headerNames <- list()
#http://r.789695.n4.nabble.com/How-to-read-plain-text-documents-into-a-vector-td901794.html
obj_list <- readLines(headersFile)
obj_list2 <- readLines(headersFile2)

#To convert to a vector, do the following:
result <- stri_extract_first(obj_list, regex="[A-z ,]+")
result2 <- stri_extract_first(obj_list2, regex="[A-z ,]+")
dtype <- stri_extract_last(obj_list, regex="[A-z ,]+")
result <- gsub(" ", "_", result)
result2 <- gsub(" ", "_", result2)

order_df <- read_csv(dataPath, col_names = result, na=c("", "?", "NULL", "NA", "Nan"), guess_max = 3400)

headersPath <- paste(rootDir, "01_data_understanding/clickstream_columns.txt", sep="/")
dataPath <- paste(rootDir, "00_raw_data/clickstream_data.csv", sep="/")
dataPath2 <- paste(rootDir, "00_raw_data/clickstream_data_part_2.csv", sep="/")

# prepare column name list
headersFile = file(headersPath, "r")
headerNames <- list()
#http://r.789695.n4.nabble.com/How-to-read-plain-text-documents-into-a-vector-td901794.html
obj_list <- readLines(headersFile)

#To convert to a vector, do the following:
result <- stri_extract_first(obj_list, regex="[A-z ,]+")
dtype <- stri_extract_last(obj_list, regex="[A-z ,]+")
result <- gsub(" ", "_", result)

dataframe <- read_csv(dataPath, col_names = result, na=c("", "?", "NULL", "NA", "Nan"), guess_max = 3400)
dataframe2 <- read_csv(dataPath2, col_names = result, na=c("", "?", "NULL", "NA", "Nan"), guess_max = 3400)


click_df <- rbind(dataframe,dataframe2)

# Parse Order Time
order_df$Order_Time <- parse_time(order_df$"Order_Line_Date_Time","%H\\:%M\\:%S")
```


# Analysis

## Data Manipulation {#dataMan}

Due to the huge size of the datasets, we will

1. create a new set `relevant_df` with the 16 most relevant columns
1. reduce the original set `order_df` by deleting all twin columns

Besides, all semicolons within the cells were simply erased.

```{r dataClean, echo=FALSE}
# Selected Column Indices
sel <- c(115,116,120,189,233,121,39,101,107,130,135,58,25,30,32,35)

relevant_df <- select(order_df,sel)

# Vergleiche Spalten, ob Dopplungen vorkommen
dataframe <- order_df

drop <- vector()
k <- 1
for (i in 1:ncol(dataframe)) {
  col_i = colnames(dataframe)[i]
  for (j in i+1:ncol(dataframe)){
    col_j = colnames(dataframe)[j]
    if(identical(dataframe[[col_i]],dataframe[[col_j]])) {
      # print(paste(col_i,col_j,sep=" = "))
      drop[k] <- i
      k <- k+1
    }
  }
}
# print(drop)
# Loesche doppelte Spalten (immer die 1.)
order_df <- subset(dataframe, select = -drop)

# Get rid of semicolons
order_df$Estimated_Income_Code <- gsub(";", "", order_df$Estimated_Income_Code)
relevant_df$Estimated_Income_Code <- gsub(";", "", relevant_df$Estimated_Income_Code)
```


## Visualisation

On a first look, the data provides the following information.

```{r firstLook, echo = FALSE, warning = FALSE}
summary_stats <- order_df %>% # start with data frame, and then ...
  summarize_at(
    .vars = c("Order_Date", "Order_Time", "Order_Amount"), # select variables, that should be in the table
    .funs = funs(min, max, mean, median, sd) # which summary statistics do you want
  ) %>%
  gather (key, value) %>% # transpose everthing, and then ...
  separate(col=key, sep="_", c("object", "feature", "stat")) %>% # make the two columns out of var name
  spread(key=stat, value=value) %>% # repeated obs into multiple columns
  select(-"object")
kable(summary_stats)
```
Thereby, date and time are less useful, as the time-format is transformed into double values that provide no information on a first look.




## Summary tables

```{r summary, echo=FALSE}

```


## Comparison of groups

```{r compare, echo=FALSE}

```


## Predictions

```{r}
library(rpart)
library(caTools)
library(rpart.plot)
require(tree)
library(party)
pred <- click_df
pred <- pred[rowSums(!is.na(pred)) > 0,colSums(!is.na(pred)) > 0]
```




## Market Basket Analysis
```{r prediction, echo=FALSE}
pred <- order_df
pred <- pred %>%
  subset(select=c(Order_ID, Product_Family_ID, Product_Level__2))
```
```{r}
library(plyr)
library(arules)
library(arulesViz)
transactionData <- ddply(pred,c("Order_ID"),
                       function(df1)paste(df1$Product_Family_ID,
                       collapse = ","))
write.csv(transactionData,"market_basket_transactions.csv", quote = FALSE, row.names = FALSE)
tr <- read.transactions('market_basket_transactions.csv', format = 'basket', sep=',')
summary(tr)
if (!require("RColorBrewer")) {
  # install color package of R
install.packages("RColorBrewer")
#include library RColorBrewer
library(RColorBrewer)
}
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.95,maxlen=10))
inspect(association.rules)
plot(association.rules, method = "graph",  engine = "htmlwidget")
```

# Conclusion
